{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70abe68d",
   "metadata": {},
   "source": [
    "# Uploading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb37ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "upload = files.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b803789e",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1edfee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652ba638",
   "metadata": {},
   "source": [
    "# Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61cebe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"Global_Dataset.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b701996",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3ed30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b20a8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"SEVERITY\"].value_counts().plot(kind=\"pie\", autopct=\"%.2f%%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a6fe39",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"SEVERITY\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dda2178",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da36b2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~(df[\"SEVERITY\"] == \"None\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2743800",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "tags = Counter(df[\"SEVERITY\"]).keys()\n",
    "tags_len = Counter(df[\"SEVERITY\"]).values()\n",
    "tag_df = pd.DataFrame(zip(tags, tags_len), columns=[\"Class\", \"Count\"])\n",
    "tag_df.plot(x=\"Class\", y=\"Count\", kind=\"bar\", legend=False, grid=False, figsize=(15, 5))\n",
    "plt.title(\"Class / Count\", fontsize=18)\n",
    "plt.xlabel(\"Class\", fontsize=15)\n",
    "plt.ylabel(\"Count\", fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf566d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc005f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_freq(CATEGORY, TEXTS):\n",
    "    freq_df = df[df[\"SEVERITY\"] == CATEGORY]\n",
    "    freq_words = freq_df[TEXTS].tolist()\n",
    "    freq_words =  [i.lower() for i in freq_words]\n",
    "    freq_punc = []\n",
    "    \n",
    "    for o in freq_words:\n",
    "        freq_punc += nltk.word_tokenize(o)\n",
    "        \n",
    "    freq_punc = [o for o in freq_punc if o not in string.punctuation]\n",
    "    freq_freq = Counter(freq_punc)\n",
    "    freq_top = freq_freq.most_common(15)\n",
    "    \n",
    "    words = [word for word, _ in freq_top]\n",
    "    counts = [counts for _, counts in freq_top]\n",
    "    \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.bar(words, counts)\n",
    "    plt.title(f\"{CATEGORY} - TOP 15 WORDS\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.xlabel(\"Words\")\n",
    "    plt.show()\n",
    "    \n",
    "    return freq_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ab8cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "low_top = word_freq(\"LOW\", \"DESCRIPTION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbe0139",
   "metadata": {},
   "outputs": [],
   "source": [
    "medium_top = word_freq(\"MEDIUM\", \"DESCRIPTION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba111aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_top = word_freq(\"HIGH\", \"DESCRIPTION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9468ebbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "critical_top = word_freq(\"CRITICAL\", \"DESCRIPTION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2387262",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "def print_wordcloud(dict_top):\n",
    "    dict_top = dict(dict_top)\n",
    "    word_cloud = WordCloud(\n",
    "        width=350,\n",
    "        height=350,\n",
    "        background_color=\"black\",\n",
    "        min_font_size=5\n",
    "    ).generate_from_frequencies(dict_top)\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.imshow(word_cloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout(pad=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171d2f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_wordcloud(low_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3bbdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_wordcloud(medium_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d63bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_wordcloud(high_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165f7513",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_wordcloud(critical_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604afd36",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2aa8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"SEVERITY\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b4b172",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_low = df[df[\"SEVERITY\"] == \"LOW\"].head(7205)\n",
    "df_medium = df[df[\"SEVERITY\"] == \"MEDIUM\"].head(7205)\n",
    "df_high = df[df[\"SEVERITY\"] == \"HIGH\"].head(7205)\n",
    "df_critical = df[df[\"SEVERITY\"] == \"CRITICAL\"].head(7205)\n",
    "\n",
    "df = pd.concat([df_low, df_medium, df_high, df_critical])\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8de0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886781fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"SEVERITY\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b674da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b0f8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download(\"stopwords\")\n",
    "stop_words_list = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d21e471",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"\\n\", \" \", text)\n",
    "    text = re.sub(r\"\\d\", \"\", text)\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    words = text.split()\n",
    "    words = [word for word in words if not word in stop_words_list]\n",
    "    words = [re.sub(r\"(.)\\1{1,}\", r\"\\1\\1\", word) for word in words]\n",
    "    words = [word.strip() for word in words if len(word.strip()) > 1]\n",
    "    text = \" \".join(words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5e4bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b420cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[\"DESCRIPTION\", \"SEVERITY\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce46d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0211ed63",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"CLEAN\"] = df[\"DESCRIPTION\"].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c122c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_low_top = word_freq(\"LOW\", \"CLEAN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea24bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_medium_top = word_freq(\"MEDIUM\", \"CLEAN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278e9feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_high_top = word_freq(\"HIGH\", \"CLEAN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5026bc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_critical_top = word_freq(\"CRITICAL\", \"CLEAN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f5d826",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_wordcloud(cleaned_low_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57796fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_wordcloud(cleaned_medium_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3ee190",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_wordcloud(cleaned_high_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccf6594",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_wordcloud(cleaned_critical_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b7fc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder().fit(df[\"SEVERITY\"])\n",
    "le_nm = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "df[\"LABELS\"] = df[\"SEVERITY\"].apply(lambda x: le_nm[x])\n",
    "df = df.drop([\"DESCRIPTION\", \"SEVERITY\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19872c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d289c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "le_nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc172ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "labels = le_nm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa8cb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.labels = [label for label in df[\"LABELS\"]]\n",
    "        self.text = [tokenizer(text, padding=\"max_length\", max_length=512, truncation=True, return_tensors=\"pt\") for text in df[\"CLEAN\"]]\n",
    "\n",
    "    def classes(self):\n",
    "        return self.labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def get_batch_labels(self, idx):\n",
    "        return np.array(self.labels[idx])\n",
    "    \n",
    "    def get_batch_texts(self, idx):\n",
    "        return self.text[idx]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        batch_texts = self.get_batch_texts(idx)\n",
    "        batch_y = self.get_batch_labels(idx)\n",
    "        return batch_texts, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387ca97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate_test_split(df):\n",
    "    np.random.seed(4242)\n",
    "    perm = np.random.permutation(df.index)\n",
    "    train_end = int(.7 * len(df.index))\n",
    "    validate_end = int(.15 * len(df.index)) + train_end\n",
    "    train = df.iloc[perm[:train_end]]\n",
    "    validate = df.iloc[perm[train_end:validate_end]]\n",
    "    test = df.iloc[perm[validate_end:]]\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c965302",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_validation, df_test = np.split(df.sample(frac=1, random_state=42), [int(.7*len(df)), int(.85*len(df))])\n",
    "print(len(df_train), len(df_validation), len(df_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe29643b",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa9e29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertClassifier(torch.nn.Module):\n",
    "    def __init__(self, dropout=0.5):\n",
    "        super(BertClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "        self.dropout = torch.nn.Dropout(dropout)\n",
    "        self.linear = torch.nn.Linear(768, 5)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        \n",
    "    def forward(self, input_id, mask):\n",
    "        _, pooled_output = self.bert(input_ids=input_id, attention_mask=mask, return_dict=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        final_layer = self.relu(linear_output)\n",
    "        return final_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4681b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 2\n",
    "model = BertClassifier()\n",
    "LR = 1e-6\n",
    "\n",
    "train, validation = Dataset(df_train), Dataset(df_validation)\n",
    "\n",
    "tdl = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n",
    "vdl = torch.utils.data.DataLoader(validation, batch_size=2)\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "model = model.cuda()\n",
    "\n",
    "for EPOCH in range(EPOCHS):\n",
    "    total_train_accuracy = 0\n",
    "    total_train_loss = 0\n",
    "    total_validation_accuracy = 0\n",
    "    total_validation_loss = 0\n",
    "    \n",
    "    from tqdm import tqdm\n",
    "    for train_input, train_label in tqdm(tdl):\n",
    "        train_label = train_label.to(device)\n",
    "        mask = train_input[\"attention_mask\"].to(device)\n",
    "        input_id = train_input[\"input_ids\"].squeeze(1).to(device)\n",
    "        output = model(input_id, mask)\n",
    "        batch_loss = criterion(output, train_label.long())\n",
    "        total_train_loss += batch_loss.item()\n",
    "        train_accuracy = (output.argmax(dim=1) == train_label).sum().item()\n",
    "        total_train_accuracy += train_accuracy\n",
    "        model.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        for val_input, val_label in tqdm(vdl):\n",
    "            val_label = val_label.to(device)\n",
    "            mask = val_input[\"attention_mask\"].to(device)\n",
    "            input_id = val_input[\"input_ids\"].squeeze(1).to(device)\n",
    "            output = model(input_id, mask)\n",
    "            batch_loss = criterion(output, val_label.long())\n",
    "            total_validation_loss += batch_loss.item()\n",
    "            validation_accuracy = (output.argmax(dim=1) == val_label).sum().item()\n",
    "            total_validation_accuracy += validation_accuracy\n",
    "            \n",
    "    print(f\"Epochs: {EPOCH + 1}\")\n",
    "    print(f\"Train Loss: {total_train_loss / len(df_train): .4f}\")\n",
    "    print(f\"Train Accuracy : {total_train_accuracy / len(df_train): .4f}\")\n",
    "    print(f\"Validation Loss: {total_validation_loss / len(df_validation): .4f}\")\n",
    "    print(f\"Validation Accuracy: {total_validation_accuracy / len(df_validation): .4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f9669f",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb350284",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = Dataset(df_test)\n",
    "\n",
    "tdl  = torch.utils.data.DataLoader(test, batch_size=2)\n",
    "device = torch.device(\"cuda\")\n",
    "model = model.cuda()\n",
    "\n",
    "total_test_accuracy = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for test_input, test_label in tdl:\n",
    "        test_label = test_label.to(device)\n",
    "        mask = test_input[\"attention_mask\"].to(device)\n",
    "        input_id = test_input[\"input_ids\"].squeeze(1).to(device)\n",
    "        output = model(input_id, mask)\n",
    "        test_accuracy = (output.argmax(dim=1) == test_label).sum().item()\n",
    "        total_test_accuracy += test_accuracy\n",
    "        \n",
    "print(f\"Test Accuracy: {total_test_accuracy / len(tdl): .4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a658090",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148548a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, sentence):\n",
    "    device = torch.device(\"cuda\")\n",
    "    model = model.cuda()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        input_id = tokenizer(sentence, padding=\"max_length\", max_length=512, truncation=True, return_tensors=\"pt\")\n",
    "        mask = input_id[\"attention_mask\"].to(device)\n",
    "        input_id = input_id[\"input_ids\"].squeeze(1).to(device)\n",
    "        output = model(input_id, mask)\n",
    "        return output.argmax(dim=1).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c8e2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRITICAL -> 0\n",
    "# HIGH -> 1\n",
    "# LOW -> 2\n",
    "# MEDIUM -> 3\n",
    "predict(model, \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fcd139",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "actuals = df_test[\"LABELS\"]\n",
    "predicted = [predict(model, df_test[\"CLEAN\"].iloc[i]) for i in range(len(df_test[\"CLEAN\"]))]\n",
    "print(classification_report(actuals, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346fb1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion_matrix(predicted, actuals, sub_classes, title=\"Confusion Matrix\", cmap=plt.cm.Blues):\n",
    "    confusion = confusion_matrix(predicted, actuals)\n",
    "    plt.imshow(confusion, interpolation=\"nearest\", cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(sub_classes))\n",
    "    plt.xticks(tick_marks, sub_classes, rotation=90)\n",
    "    plt.yticks(tick_marks, sub_classes)\n",
    "    \n",
    "    for i, j in itertools.product(range(confusion.shape[0]), range(confusion.shape[1])):\n",
    "        plt.text(j, i, confusion[i, j], horizontalalignment=\"center\", color=\"black\")\n",
    "        \n",
    "    plt.rcParams[\"figure.figsize\"] = (15, 5)\n",
    "    plt.ylabel(\"Actuals\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69c28c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(predicted, actuals, sub_classes=le_nm.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe891a03",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc196397",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "\n",
    "model_name = \"bert_cve.pt\"\n",
    "path = F\"/content/gdrive/My Drive/{model_name}\"\n",
    "torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a563641",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
